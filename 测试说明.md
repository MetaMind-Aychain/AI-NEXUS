# 多AI协作系统 - 测试说明

## 🎯 测试概述

本测试套件包含完整的多AI协作系统功能验证，支持多种测试模式，无需OpenAI API密钥即可运行基础测试。

## 🚀 快速开始

### 1. 环境检查
```bash
# 检查系统环境是否满足要求
python run_tests.py --mode check
```

### 2. 快速测试（推荐）
```bash
# 运行核心功能测试，大约需要1-2分钟
python run_tests.py --mode quick
```

### 3. 完整测试
```bash
# 运行所有测试用例，大约需要3-5分钟
python run_tests.py --mode full
```

### 4. 演示模式
```bash
# 展示系统各个AI组件的工作流程
python run_tests.py --mode demo
```

### 5. 性能测试
```bash
# 测试系统性能指标
python run_tests.py --mode performance
```

## 📋 测试内容详解

### 单元测试 (Unit Tests)
- ✅ **共享记忆系统**: 事件存储、知识管理、相似案例检索
- ✅ **监管AI**: 代码质量分析、问题诊断、风险预警
- ✅ **测试AI**: 测试用例生成、执行、失败诊断
- ✅ **部署AI**: 项目打包、配置生成、部署管理
- ✅ **增强开发AI**: 开发计划制定、监督下的代码生成
- ✅ **多AI编排器**: 工作流程协调、状态管理
- ✅ **服务器接口**: 远程部署管理、状态监控

### 集成测试 (Integration Tests)
- ✅ **多AI协作流程**: 验证不同AI角色之间的协作
- ✅ **端到端工作流**: 从需求到部署的完整流程
- ✅ **错误恢复机制**: 异常情况下的系统行为

### 性能测试 (Performance Tests)
- ✅ **数据库性能**: 大量事件的存储和查询速度
- ✅ **相似案例检索**: 智能匹配算法的效率
- ✅ **内存使用**: 系统资源消耗监控

## 🎭 演示模式详解

演示模式会展示一个完整的任务管理系统开发流程：

```bash
python run_tests.py --mode demo
```

**演示内容包括：**
1. 📝 需求分析：将用户需求转换为开发任务
2. 🤖 监管AI：分析代码质量，提供改进建议
3. 🧪 测试AI：自动生成测试用例
4. 🚀 部署AI：生成部署配置和Docker文件
5. 💾 记忆系统：展示知识积累和经验学习

## 🔧 测试配置

### 模拟模式 (Mock Mode)
- **优势**: 无需API密钥，快速验证功能
- **适用**: 开发测试、CI/CD集成
- **限制**: 使用预设响应，不能测试真实AI交互

### 真实模式 (Real Mode)
- **优势**: 测试真实AI交互和响应质量
- **要求**: 需要设置 `OPENAI_API_KEY` 环境变量
- **成本**: 会产生少量API调用费用（通常 < $0.10）

## 📊 测试结果解读

### 成功指标
```
🎉 所有测试通过！系统运行正常
📊 单元测试结果:
   总计: 25 个测试
   成功: 25 个
   失败: 0 个
   错误: 0 个
```

### 性能基准
```
📊 插入100个事件耗时: 0.045秒
📊 查询100个事件耗时: 0.012秒
📊 相似案例查找耗时: 0.089秒
```

## 🐛 常见问题

### 1. 模块导入错误
```bash
ModuleNotFoundError: No module named 'xxx'
```
**解决方案**: 确保在项目根目录运行，或添加路径：
```bash
export PYTHONPATH=$PYTHONPATH:$(pwd)
python run_tests.py
```

### 2. 权限错误
```bash
PermissionError: [Errno 13] Permission denied
```
**解决方案**: 检查临时目录权限：
```bash
chmod 755 /tmp
# 或使用自定义临时目录
export TMPDIR=./temp
```

### 3. SQLite锁定错误
```bash
sqlite3.OperationalError: database is locked
```
**解决方案**: 确保没有其他进程使用数据库文件，或重启测试。

### 4. 内存不足
```bash
MemoryError: Unable to allocate array
```
**解决方案**: 
- 关闭其他程序释放内存
- 使用 `--mode quick` 进行轻量级测试

## 🎯 自定义测试

### 创建自定义测试用例
```python
import unittest
from test_multi_ai_system import MockAI
from multi_ai_system.ai.supervisor_ai import SupervisorAI

class MyCustomTest(unittest.TestCase):
    def test_custom_feature(self):
        # 你的测试代码
        mock_ai = MockAI()
        supervisor = SupervisorAI(mock_ai)
        # 进行测试...
```

### 运行特定测试
```python
# 只运行特定测试文件
python -m unittest test_multi_ai_system.TestSupervisorAI

# 只运行特定测试方法
python -m unittest test_multi_ai_system.TestSupervisorAI.test_analyze_quality
```

## 📈 持续集成 (CI/CD)

### GitHub Actions 示例
```yaml
name: Multi-AI System Tests
on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: 3.9
    - name: Install dependencies
      run: pip install -r requirements.txt
    - name: Run tests
      run: python run_tests.py --mode full
```

## 🔍 测试覆盖率

查看测试覆盖率：
```bash
# 安装coverage
pip install coverage

# 运行带覆盖率的测试
coverage run test_multi_ai_system.py
coverage report
coverage html  # 生成HTML报告
```

## 📝 测试报告

### 自动生成测试报告
```bash
# 生成详细测试报告
python run_tests.py --mode full --verbose > test_report.txt 2>&1
```

### 报告内容包括
- 各组件测试结果
- 性能指标统计  
- 错误详情和堆栈跟踪
- 系统资源使用情况

## 💡 最佳实践

1. **开发前测试**: 修改代码前运行快速测试
2. **提交前测试**: 提交代码前运行完整测试
3. **定期性能测试**: 每周运行性能测试检查退化
4. **环境隔离**: 使用虚拟环境避免依赖冲突
5. **日志记录**: 保存测试日志便于问题追踪

## 🆘 获取帮助

- 📖 查看 [README_多AI协作系统.md](README_多AI协作系统.md) 了解系统详情
- 🐛 在 GitHub Issues 报告问题
- 💬 在 Discussions 参与讨论
- 📧 联系开发团队获取支持

---

**多AI协作开发系统** - 让AI为您构建完整的软件项目！ 🚀