# å¤šAIåä½œå¼€å‘ç³»ç»Ÿ

åŸºäºGPT-Engineerçš„æ·±åº¦é›†æˆå¤šAIåä½œå¼€å‘å¹³å°ï¼Œå®ç°ä»éœ€æ±‚åˆ°éƒ¨ç½²çš„å…¨è‡ªåŠ¨åŒ–è½¯ä»¶å¼€å‘æµç¨‹ã€‚

## ğŸš€ ç³»ç»Ÿæ¦‚è¿°

æœ¬ç³»ç»Ÿå°†GPT-Engineerä»å•ä¸€çš„ä»£ç ç”Ÿæˆå·¥å…·å‡çº§ä¸ºå®Œæ•´çš„AIé©±åŠ¨è½¯ä»¶å¼€å‘å¹³å°ï¼Œé€šè¿‡å¤šä¸ªä¸“ä¸šAIè§’è‰²çš„åä½œï¼Œå®ç°çœŸæ­£æ„ä¹‰ä¸Šçš„è‡ªåŠ¨åŒ–è½¯ä»¶å¼€å‘ã€‚

### æ ¸å¿ƒç‰¹æ€§

- **ğŸ¤– å¤šAIåä½œ**: æ–‡æ¡£AIã€å¼€å‘AIã€ç›‘ç®¡AIã€æµ‹è¯•AIã€å‰ç«¯AIã€éƒ¨ç½²AIç­‰ä¸“ä¸šè§’è‰²åä½œ
- **ğŸ“‹ å…¨æµç¨‹è‡ªåŠ¨åŒ–**: ä»éœ€æ±‚åˆ†æåˆ°éƒ¨ç½²ç›‘æ§çš„å®Œæ•´è‡ªåŠ¨åŒ–æµç¨‹
- **ğŸ§  æ™ºèƒ½è®°å¿†ç³»ç»Ÿ**: ç´¯ç§¯å¼€å‘ç»éªŒï¼ŒæŒç»­å­¦ä¹ å’Œä¼˜åŒ–
- **ğŸ” è´¨é‡ä¿è¯**: è‡ªåŠ¨åŒ–ä»£ç è´¨é‡åˆ†æå’Œæµ‹è¯•éªŒè¯
- **ğŸ“¦ ä¸€é”®éƒ¨ç½²**: è‡ªåŠ¨åŒ–é¡¹ç›®æ‰“åŒ…å’Œå¤šå¹³å°éƒ¨ç½²
- **ğŸ“Š å®æ—¶ç›‘æ§**: éƒ¨ç½²çŠ¶æ€ç›‘æ§å’Œæ€§èƒ½åˆ†æ

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

```mermaid
graph TD
    A[ç”¨æˆ·è¾“å…¥éœ€æ±‚] --> B[æ–‡æ¡£AIç”Ÿæˆæ–‡æ¡£]
    B --> C[ç”¨æˆ·å®¡æ ¸/ä¿®æ”¹æ–‡æ¡£]
    C --> D[å¼€å‘AIåˆ¶å®šè®¡åˆ’]
    D --> E[å¼€å‘AIç¼–å†™ä»£ç ]
    E --> F[ç›‘ç®¡AIç›‘ç£/è®°å¿†]
    F --> G[æµ‹è¯•AIæ‰§è¡Œæµ‹è¯•]
    G --> H{æµ‹è¯•é€šè¿‡?}
    H -->|å¦| E
    H -->|æ˜¯| I[å‰ç«¯AIå¼€å‘UI]
    I --> J[ç”¨æˆ·è°ƒæ•´UI]
    J --> K[é›†æˆå‰åç«¯]
    K --> L[éƒ¨ç½²AIæ‰“åŒ…é¡¹ç›®]
    L --> M[æœåŠ¡å™¨AIéƒ¨ç½²]
    M --> N[æµ‹è¯•AIæœ€ç»ˆè¯„åˆ†]
    N --> O[é€šçŸ¥ç”¨æˆ·å®Œæˆ]
    
    F -.-> Q[å…±äº«è®°å¿†åº“]
    E -.-> Q
    G -.-> Q
    Q -.-> F
```

### æ ¸å¿ƒç»„ä»¶

#### 1. **å¢å¼ºå¼€å‘AI** (`EnhancedDevAI`)
åŸºäºGPT-Engineerçš„SimpleAgentæ‰©å±•ï¼š
- é›†æˆç›‘ç®¡AIç›‘ç£æœºåˆ¶
- æ”¯æŒæµ‹è¯•åé¦ˆçš„è¿­ä»£å¼€å‘
- è®¿é—®å…±äº«è®°å¿†çš„å†å²ç»éªŒ
- æ™ºèƒ½ä»£ç ç”Ÿæˆå’Œæ”¹è¿›

#### 2. **ç›‘ç®¡AI** (`SupervisorAI`)
è´Ÿè´£è´¨é‡æ§åˆ¶å’Œè¿›åº¦ç›‘ç£ï¼š
- å®æ—¶ä»£ç è´¨é‡åˆ†æ
- å¼€å‘è¿›åº¦ç›‘æ§
- é£é™©é¢„è­¦å’Œå»ºè®®
- å¼€å‘å†å²è®°å½•ç®¡ç†

#### 3. **æµ‹è¯•AI** (`TestAI`)
è‡ªåŠ¨åŒ–æµ‹è¯•å’ŒéªŒè¯ï¼š
- æ™ºèƒ½æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ
- è‡ªåŠ¨åŒ–æµ‹è¯•æ‰§è¡Œ
- æµ‹è¯•è¦†ç›–ç‡åˆ†æ
- å¤±è´¥åŸå› è¯Šæ–­

#### 4. **éƒ¨ç½²AI** (`DeployAI`)
é¡¹ç›®æ‰“åŒ…å’Œéƒ¨ç½²ï¼š
- å¤šæ ¼å¼é¡¹ç›®æ‰“åŒ…ï¼ˆDockerã€ZIPã€TARç­‰ï¼‰
- å¤šå¹³å°éƒ¨ç½²æ”¯æŒ
- é…ç½®æ–‡ä»¶è‡ªåŠ¨ç”Ÿæˆ
- éƒ¨ç½²çŠ¶æ€ç›‘æ§

#### 5. **å…±äº«è®°å¿†ç³»ç»Ÿ** (`SharedMemoryManager`)
çŸ¥è¯†ç§¯ç´¯å’Œç»éªŒå­¦ä¹ ï¼š
- å¼€å‘äº‹ä»¶å­˜å‚¨å’Œæ£€ç´¢
- ç›¸ä¼¼æ¡ˆä¾‹æ™ºèƒ½åŒ¹é…
- çŸ¥è¯†åº“æŒç»­æ›´æ–°
- é¡¹ç›®çŠ¶æ€è·Ÿè¸ª

#### 6. **å¤šAIç¼–æ’å™¨** (`MultiAIOrchestrator`)
å·¥ä½œæµç¨‹åè°ƒå’Œç®¡ç†ï¼š
- å¤šAIåä½œç¼–æ’
- å·¥ä½œæµçŠ¶æ€ç®¡ç†
- é”™è¯¯å¤„ç†å’Œæ¢å¤
- è¿›åº¦è·Ÿè¸ªå’ŒæŠ¥å‘Š

## ğŸ“ é¡¹ç›®ç»“æ„

```
multi_ai_system/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ base_interfaces.py      # åŸºç¡€æ¥å£å®šä¹‰
â”‚   â””â”€â”€ enhanced_dev_ai.py      # å¢å¼ºå¼€å‘AIå®ç°
â”œâ”€â”€ ai/
â”‚   â”œâ”€â”€ supervisor_ai.py        # ç›‘ç®¡AIå®ç°
â”‚   â”œâ”€â”€ test_ai.py             # æµ‹è¯•AIå®ç°
â”‚   â””â”€â”€ deploy_ai.py           # éƒ¨ç½²AIå®ç°
â”œâ”€â”€ memory/
â”‚   â””â”€â”€ shared_memory.py       # å…±äº«è®°å¿†ç³»ç»Ÿ
â”œâ”€â”€ deployment/
â”‚   â””â”€â”€ server_interface.py   # æœåŠ¡å™¨AIæ¥å£
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ usage_example.py      # ä½¿ç”¨ç¤ºä¾‹
â”œâ”€â”€ orchestrator.py           # å¤šAIç¼–æ’å™¨
â””â”€â”€ README_å¤šAIåä½œç³»ç»Ÿ.md    # æœ¬æ–‡æ¡£
```

## ğŸš¦ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# å®‰è£…ä¾èµ–
pip install gpt-engineer openai langchain python-dotenv

# è®¾ç½®ç¯å¢ƒå˜é‡
export OPENAI_API_KEY="your-openai-api-key"
```

### 2. åŸºç¡€ä½¿ç”¨

```python
import asyncio
from multi_ai_system.orchestrator import MultiAIOrchestrator

async def main():
    # ç”¨æˆ·éœ€æ±‚
    requirement = """
    å¼€å‘ä¸€ä¸ªä»»åŠ¡ç®¡ç†ç³»ç»Ÿï¼ŒåŒ…å«ï¼š
    - ä»»åŠ¡çš„å¢åˆ æ”¹æŸ¥
    - ç”¨æˆ·è®¤è¯
    - Webç•Œé¢
    - RESTful API
    """
    
    # åˆ›å»ºç¼–æ’å™¨
    orchestrator = MultiAIOrchestrator(
        work_dir="./my_project",
        ai_config={'model_name': 'gpt-4o'}
    )
    
    # æ‰§è¡Œå¼€å‘æµç¨‹
    result = await orchestrator.execute_workflow(
        user_requirement=requirement,
        workflow_options={
            'include_frontend': True,
            'auto_deploy': True,
            'deploy_platform': 'docker'
        }
    )
    
    print(f"é¡¹ç›®å¼€å‘å®Œæˆï¼è¯„åˆ†: {result.final_score}/100")
    if result.deployment and result.deployment.url:
        print(f"è®¿é—®åœ°å€: {result.deployment.url}")

# è¿è¡Œ
asyncio.run(main())
```

### 3. é«˜çº§é…ç½®

```python
# è‡ªå®šä¹‰AIé…ç½®
ai_config = {
    'model_name': 'gpt-4o',
    'temperature': 0.1
}

# å·¥ä½œæµé…ç½®
workflow_config = {
    'max_dev_iterations': 5,        # æœ€å¤§å¼€å‘è¿­ä»£æ¬¡æ•°
    'package_type': 'docker',       # æ‰“åŒ…ç±»å‹
    'include_frontend': True,       # æ˜¯å¦åŒ…å«å‰ç«¯
    'auto_deploy': False           # æ˜¯å¦è‡ªåŠ¨éƒ¨ç½²
}

orchestrator = MultiAIOrchestrator(
    work_dir="./advanced_project",
    ai_config=ai_config,
    workflow_config=workflow_config
)
```

## ğŸ”§ é«˜çº§åŠŸèƒ½

### 1. ç›‘ç®¡AIè´¨é‡æ§åˆ¶

```python
from multi_ai_system.ai.supervisor_ai import SupervisorAI
from gpt_engineer.core.ai import AI

# åˆ›å»ºç›‘ç®¡AI
supervisor = SupervisorAI(AI())

# åˆ†æä»£ç è´¨é‡
quality_report = supervisor.analyze_quality(files_dict)
print(f"è´¨é‡è¯„åˆ†: {quality_report.overall_score}/100")
print(f"å‘ç°é—®é¢˜: {len(quality_report.issues)} ä¸ª")
```

### 2. æµ‹è¯•AIè‡ªåŠ¨åŒ–æµ‹è¯•

```python
from multi_ai_system.ai.test_ai import TestAI

# åˆ›å»ºæµ‹è¯•AI
test_ai = TestAI(AI())

# ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
test_files = test_ai.generate_tests(code_files, requirements)

# æ‰§è¡Œæµ‹è¯•
test_result = test_ai.execute_tests(code_files)
print(f"æµ‹è¯•é€šè¿‡ç‡: {test_result.passed_tests}/{test_result.total_tests}")
```

### 3. å…±äº«è®°å¿†ç³»ç»Ÿ

```python
from multi_ai_system.memory.shared_memory import SharedMemoryManager

# åˆ›å»ºè®°å¿†ç®¡ç†å™¨
memory = SharedMemoryManager("./memory")

# æŸ¥æ‰¾ç›¸ä¼¼æ¡ˆä¾‹
context = {'requirements': {'type': 'web_app', 'tech': 'python'}}
similar_cases = memory.find_similar_cases(context)

# è·å–ç»Ÿè®¡ä¿¡æ¯
stats = memory.get_statistics()
print(f"å†å²é¡¹ç›®æ•°: {stats['events']['projects']}")
```

### 4. æœåŠ¡å™¨éƒ¨ç½²æ¥å£

```python
from multi_ai_system.deployment.server_interface import ServerAIInterface

# é…ç½®æœåŠ¡å™¨
server_config = {
    'api_base_url': 'https://your-server.com',
    'api_key': 'your-api-key'
}

server_interface = ServerAIInterface(server_config)

# ä¸Šä¼ å’Œéƒ¨ç½²é¡¹ç›®
upload_result = server_interface.upload_project_package(package_result)
deploy_result = server_interface.deploy_project(upload_result['upload_id'])
```

## ğŸ“Š å·¥ä½œæµé˜¶æ®µ

ç³»ç»ŸåŒ…å«ä»¥ä¸‹9ä¸ªä¸»è¦é˜¶æ®µï¼š

1. **æ–‡æ¡£ç”Ÿæˆ** - å°†ç”¨æˆ·éœ€æ±‚è½¬æ¢ä¸ºç»“æ„åŒ–éœ€æ±‚æ–‡æ¡£
2. **å¼€å‘è®¡åˆ’** - åˆ¶å®šè¯¦ç»†çš„å¼€å‘è®¡åˆ’å’Œä»»åŠ¡åˆ†è§£
3. **è¿­ä»£å¼€å‘** - åŸºäºè®¡åˆ’è¿›è¡Œä»£ç ç”Ÿæˆå’Œè¿­ä»£æ”¹è¿›
4. **æµ‹è¯•éªŒè¯** - è‡ªåŠ¨ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹å¹¶æ‰§è¡ŒéªŒè¯
5. **å‰ç«¯å¼€å‘** - ç”Ÿæˆç”¨æˆ·ç•Œé¢ï¼ˆå¯é€‰ï¼‰
6. **ç³»ç»Ÿé›†æˆ** - æ•´åˆå‰åç«¯ä»£ç 
7. **é¡¹ç›®æ‰“åŒ…** - ç”Ÿæˆéƒ¨ç½²åŒ…å’Œé…ç½®æ–‡ä»¶
8. **è‡ªåŠ¨éƒ¨ç½²** - éƒ¨ç½²åˆ°ç›®æ ‡ç¯å¢ƒï¼ˆå¯é€‰ï¼‰
9. **æœ€ç»ˆè¯„ä¼°** - ç»¼åˆè¯„ä¼°é¡¹ç›®è´¨é‡å’Œæ€§èƒ½

## ğŸ” ç›‘æ§å’Œåˆ†æ

### å®æ—¶è¿›åº¦è·Ÿè¸ª

```python
# è·å–å½“å‰ä¼šè¯çŠ¶æ€
status = orchestrator.get_session_status()
print(f"å½“å‰é˜¶æ®µ: {status['current_stage']}")
print(f"å®Œæˆè¿›åº¦: {status['progress']}%")
```

### äº‹ä»¶å¤„ç†æœºåˆ¶

```python
# æ³¨å†Œè‡ªå®šä¹‰äº‹ä»¶å¤„ç†å™¨
async def custom_handler(event):
    print(f"äº‹ä»¶: {event.event_type} - {event.description}")

orchestrator.register_event_handler('code_generation', custom_handler)
```

### éƒ¨ç½²ç›‘æ§

```python
# ç›‘æ§éƒ¨ç½²çŠ¶æ€
monitoring_data = server_interface.monitor_deployment(deployment_id)
print(f"æœåŠ¡çŠ¶æ€: {monitoring_data['health']}")
print(f"å“åº”æ—¶é—´: {monitoring_data['metrics']['response_time']}ms")

# è·å–éƒ¨ç½²æ—¥å¿—
logs = server_interface.get_deployment_logs(deployment_id, lines=100)
```

## ğŸ› ï¸ è‡ªå®šä¹‰æ‰©å±•

### 1. æ·»åŠ æ–°çš„AIè§’è‰²

```python
from multi_ai_system.core.base_interfaces import BaseSupervisorAI

class CustomAI(BaseSupervisorAI):
    def custom_analysis(self, code):
        # å®ç°è‡ªå®šä¹‰åˆ†æé€»è¾‘
        pass
```

### 2. æ‰©å±•å·¥ä½œæµé˜¶æ®µ

```python
class CustomOrchestrator(MultiAIOrchestrator):
    async def _stage_custom_processing(self, data):
        # æ·»åŠ è‡ªå®šä¹‰å¤„ç†é˜¶æ®µ
        pass
```

### 3. è‡ªå®šä¹‰éƒ¨ç½²å¹³å°

```python
class CustomDeployAI(DeployAI):
    def _deploy_to_custom_platform(self, package, config, deployment_id):
        # å®ç°è‡ªå®šä¹‰éƒ¨ç½²é€»è¾‘
        pass
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### 1. å¹¶è¡Œå¤„ç†

ç³»ç»Ÿæ”¯æŒå¤šä¸ªAIè§’è‰²çš„å¹¶è¡Œå·¥ä½œï¼Œå¯é€šè¿‡é…ç½®ä¼˜åŒ–æ€§èƒ½ï¼š

```python
workflow_config = {
    'parallel_testing': True,      # å¹¶è¡Œæ‰§è¡Œæµ‹è¯•
    'concurrent_analysis': True,   # å¹¶å‘è´¨é‡åˆ†æ
    'async_deployment': True       # å¼‚æ­¥éƒ¨ç½²
}
```

### 2. ç¼“å­˜æœºåˆ¶

å…±äº«è®°å¿†ç³»ç»Ÿå†…ç½®ç¼“å­˜æœºåˆ¶ï¼Œå‡å°‘é‡å¤è®¡ç®—ï¼š

```python
# ç¼“å­˜é…ç½®
memory_config = {
    'cache_ttl': 3600,           # ç¼“å­˜æœ‰æ•ˆæœŸï¼ˆç§’ï¼‰
    'max_cache_size': 1000,      # æœ€å¤§ç¼“å­˜æ¡ç›®æ•°
    'enable_similarity_cache': True  # å¯ç”¨ç›¸ä¼¼æ€§ç¼“å­˜
}
```

## ğŸ”’ å®‰å…¨è€ƒè™‘

### 1. APIå¯†é’¥ç®¡ç†

```python
# ä½¿ç”¨ç¯å¢ƒå˜é‡å­˜å‚¨æ•æ„Ÿä¿¡æ¯
import os
from dotenv import load_dotenv

load_dotenv()

server_config = {
    'api_key': os.getenv('SERVER_API_KEY'),
    'openai_key': os.getenv('OPENAI_API_KEY')
}
```

### 2. ä»£ç å®‰å…¨æ£€æŸ¥

ç›‘ç®¡AIå†…ç½®å®‰å…¨æ¨¡å¼æ£€æŸ¥ï¼š

```python
# å®‰å…¨é£é™©æ£€æµ‹
risk_patterns = {
    'security_risks': [
        r'password\s*=\s*["\'][^"\']+["\']',  # ç¡¬ç¼–ç å¯†ç 
        r'api_key\s*=\s*["\'][^"\']+["\']',   # ç¡¬ç¼–ç APIå¯†é’¥
    ]
}
```

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **APIå¯†é’¥é”™è¯¯**
   ```bash
   export OPENAI_API_KEY="your-valid-key"
   ```

2. **å†…å­˜ä¸è¶³**
   ```python
   # æ¸…ç†æ—§æ•°æ®
   memory.cleanup_old_data(days_to_keep=7)
   ```

3. **éƒ¨ç½²å¤±è´¥**
   ```python
   # æ£€æŸ¥éƒ¨ç½²æ—¥å¿—
   logs = server_interface.get_deployment_logs(deployment_id)
   ```

### è°ƒè¯•æ¨¡å¼

```python
import logging

# å¯ç”¨è¯¦ç»†æ—¥å¿—
logging.basicConfig(level=logging.DEBUG)

# å¯ç”¨AIè°ƒè¯•æ¨¡å¼
ai_config = {'debug': True, 'verbose': True}
```

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿è´¡çŒ®ä»£ç å’Œæ”¹è¿›å»ºè®®ï¼

### å¼€å‘ç¯å¢ƒè®¾ç½®

```bash
# å…‹éš†é¡¹ç›®
git clone <repository-url>
cd multi-ai-system

# å®‰è£…å¼€å‘ä¾èµ–
pip install -r requirements-dev.txt

# è¿è¡Œæµ‹è¯•
pytest tests/

# ä»£ç æ ¼å¼åŒ–
black multi_ai_system/
```

### è´¡çŒ®æµç¨‹

1. Fork é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/amazing-feature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add amazing feature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/amazing-feature`)
5. åˆ›å»º Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäº MIT è®¸å¯è¯å¼€æº - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

## ğŸ™ è‡´è°¢

- æ„Ÿè°¢ [GPT-Engineer](https://github.com/gpt-engineer-org/gpt-engineer) é¡¹ç›®æä¾›çš„åŸºç¡€æ¡†æ¶
- æ„Ÿè°¢ OpenAI æä¾›çš„å¼ºå¤§è¯­è¨€æ¨¡å‹
- æ„Ÿè°¢æ‰€æœ‰è´¡çŒ®è€…çš„æ”¯æŒå’Œåé¦ˆ

## ğŸ“ è”ç³»æˆ‘ä»¬

- é¡¹ç›®ä¸»é¡µ: [GitHub Repository](https://github.com/your-org/multi-ai-system)
- é—®é¢˜åé¦ˆ: [Issues](https://github.com/your-org/multi-ai-system/issues)
- è®¨è®ºåŒº: [Discussions](https://github.com/your-org/multi-ai-system/discussions)

---

**å¤šAIåä½œå¼€å‘ç³»ç»Ÿ** - è®©AIä¸ºæ‚¨æ„å»ºå®Œæ•´çš„è½¯ä»¶é¡¹ç›®ï¼ ğŸš€