#!/usr/bin/env python3
"""
æ·±åº¦é›†æˆæµ‹è¯•

éªŒè¯GPT-ENGINEERä¸å‡çº§ç‰ˆAIçš„æ·±åº¦é›†æˆåŠŸèƒ½
"""

import os
import sys
import tempfile
from pathlib import Path

# æ·»åŠ è·¯å¾„
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

# æ¨¡æ‹Ÿç¼ºå¤±çš„æ¨¡å—ï¼Œé¿å…å¯¼å…¥é”™è¯¯
class MockBackoff:
    @staticmethod
    def on_exception(*args, **kwargs):
        def decorator(func):
            return func
        return decorator

# åœ¨å¯¼å…¥ä¹‹å‰è®¾ç½®mock
sys.modules['backoff'] = MockBackoff()

try:
    from gpt_engineer.core.ai import AI
    from gpt_engineer.core.files_dict import FilesDict
    from gpt_engineer.core.default.disk_memory import DiskMemory
    from gpt_engineer.core.default.disk_execution_env import DiskExecutionEnv
    from gpt_engineer.core.preprompts_holder import PrepromptsHolder
    
    from multi_ai_system.core.deep_integration import DeepIntegratedDevAI, DeepIntegrationManager
    from multi_ai_system.memory.shared_memory import SharedMemoryManager
    
    HAS_DEPENDENCIES = True
except ImportError as e:
    print(f"âš ï¸ ä¾èµ–ç¼ºå¤±: {e}")
    HAS_DEPENDENCIES = False


class DeepIntegrationTester:
    """æ·±åº¦é›†æˆæµ‹è¯•å™¨"""
    
    def __init__(self):
        self.test_results = []
        self.passed_tests = 0
        self.total_tests = 0
    
    def log_test(self, test_name: str, success: bool, message: str = "", details: any = None):
        """è®°å½•æµ‹è¯•ç»“æœ"""
        self.total_tests += 1
        if success:
            self.passed_tests += 1
            status = "âœ… PASS"
        else:
            status = "âŒ FAIL"
        
        result = {
            "name": test_name,
            "success": success,
            "message": message,
            "details": details
        }
        
        self.test_results.append(result)
        print(f"{status} {test_name}: {message}")
    
    def test_mock_ai_functionality(self):
        """æµ‹è¯•æ¨¡æ‹ŸAIåŠŸèƒ½ï¼ˆé¿å…APIè°ƒç”¨ï¼‰"""
        try:
            # åˆ›å»ºæ¨¡æ‹ŸAIç±»
            class MockAI:
                def __init__(self, model_name="mock", temperature=0.1):
                    self.model_name = model_name
                    self.temperature = temperature
                
                def start(self, system: str, user: str, step_name: str):
                    # æ¨¡æ‹ŸAIå“åº”
                    class MockMessage:
                        def __init__(self, content):
                            self.content = content
                    
                    return [MockMessage(f"# Mock response for {step_name}\n\n```python\nprint('Hello, World!')\n```")]
            
            mock_ai = MockAI()
            
            self.log_test(
                "æ¨¡æ‹ŸAIåˆ›å»º",
                True,
                f"æ¨¡å‹: {mock_ai.model_name}",
                {"model": mock_ai.model_name, "temp": mock_ai.temperature}
            )
            
            return mock_ai
            
        except Exception as e:
            self.log_test("æ¨¡æ‹ŸAIåˆ›å»º", False, f"å¤±è´¥: {str(e)}")
            return None
    
    def test_deep_integration_manager(self):
        """æµ‹è¯•æ·±åº¦é›†æˆç®¡ç†å™¨"""
        try:
            with tempfile.TemporaryDirectory() as temp_dir:
                manager = DeepIntegrationManager(temp_dir)
                
                # æµ‹è¯•åŸºç¡€åˆå§‹åŒ–
                self.log_test(
                    "æ·±åº¦é›†æˆç®¡ç†å™¨-åˆå§‹åŒ–",
                    True,
                    f"å·¥ä½œç›®å½•: {manager.work_dir}",
                    {"work_dir": str(manager.work_dir)}
                )
                
                # æµ‹è¯•é›†æˆæ‘˜è¦
                summary = manager.get_integration_summary()
                
                summary_success = (
                    isinstance(summary, dict) and
                    "gpt_engineer_core" in summary and
                    "upgraded_components" in summary
                )
                
                self.log_test(
                    "æ·±åº¦é›†æˆç®¡ç†å™¨-æ‘˜è¦ç”Ÿæˆ",
                    summary_success,
                    f"æ‘˜è¦å­—æ®µ: {len(summary)}",
                    summary
                )
                
                return manager
                
        except Exception as e:
            self.log_test("æ·±åº¦é›†æˆç®¡ç†å™¨", False, f"æµ‹è¯•å¤±è´¥: {str(e)}")
            return None
    
    def test_simulated_deep_integration(self):
        """æµ‹è¯•æ¨¡æ‹Ÿæ·±åº¦é›†æˆæµç¨‹"""
        try:
            with tempfile.TemporaryDirectory() as temp_dir:
                # 1. åˆ›å»ºç®¡ç†å™¨
                manager = DeepIntegrationManager(temp_dir)
                
                # 2. åˆ›å»ºæ¨¡æ‹Ÿç»„ä»¶
                mock_ai = self.test_mock_ai_functionality()
                if not mock_ai:
                    return False
                
                # 3. æ¨¡æ‹Ÿè®¾ç½®æ ¸å¿ƒç»„ä»¶
                class MockMemory:
                    def __init__(self):
                        self._data = {}
                    
                    def to_dict(self):
                        return self._data.copy()
                    
                    def update(self, data):
                        self._data.update(data)
                    
                    def __getitem__(self, key):
                        return self._data[key]
                    
                    def __setitem__(self, key, value):
                        self._data[key] = value
                
                class MockExecutionEnv:
                    def run(self, *args, **kwargs):
                        return "Mock execution result"
                
                class MockPrepromptsHolder:
                    def load(self):
                        return {
                            "roadmap": "Mock roadmap prompt",
                            "generate": "Mock generate prompt",
                            "file_format": "Mock file format",
                            "philosophy": "Mock philosophy"
                        }
                
                # 4. è®¾ç½®æ¨¡æ‹Ÿç»„ä»¶
                manager.ai = mock_ai
                manager.memory = MockMemory()
                manager.execution_env = MockExecutionEnv()
                manager.preprompts_holder = MockPrepromptsHolder()
                
                # 5. åˆ›å»ºæ¨¡æ‹Ÿå‡çº§AI
                class MockSupervisorAI:
                    async def start_supervision(self, dev_plan):
                        return "mock_supervision_id"
                    
                    async def analyze_quality(self, supervision_id, files):
                        class MockQualityReport:
                            def __init__(self):
                                self.overall_score = 0.85
                                self.suggestions = ["æé«˜ä»£ç æ³¨é‡Šè´¨é‡"]
                                self.detailed_analysis = "ä»£ç è´¨é‡è‰¯å¥½"
                        return MockQualityReport()
                
                class MockTestAI:
                    async def generate_tests(self, files, requirements):
                        return FilesDict({"test_example.py": "def test_example(): assert True"})
                
                class MockSharedMemory:
                    async def store_memory(self, key, data):
                        pass
                
                # 6. è®¾ç½®å‡çº§ç»„ä»¶
                manager.setup_upgraded_ai_components(
                    supervisor_ai=MockSupervisorAI(),
                    test_ai=MockTestAI(),
                    shared_memory=MockSharedMemory()
                )
                
                # 7. æµ‹è¯•é›†æˆæ‘˜è¦
                integration_summary = manager.get_integration_summary()
                
                integration_success = (
                    integration_summary["gpt_engineer_core"]["ai_ready"] and
                    integration_summary["gpt_engineer_core"]["memory_ready"] and
                    integration_summary["upgraded_components"]["supervisor_ai"] and
                    integration_summary["upgraded_components"]["test_ai"]
                )
                
                self.log_test(
                    "æ¨¡æ‹Ÿæ·±åº¦é›†æˆæµç¨‹",
                    integration_success,
                    "æ‰€æœ‰ç»„ä»¶å°±ç»ª",
                    integration_summary
                )
                
                return integration_success
                
        except Exception as e:
            self.log_test("æ¨¡æ‹Ÿæ·±åº¦é›†æˆæµç¨‹", False, f"æµ‹è¯•å¤±è´¥: {str(e)}")
            return False
    
    def test_file_operations_simulation(self):
        """æµ‹è¯•æ–‡ä»¶æ“ä½œæ¨¡æ‹Ÿ"""
        try:
            # æ¨¡æ‹Ÿæ–‡ä»¶æ“ä½œ
            test_files = FilesDict({
                "main.py": "def main():\n    print('Hello from deep integration!')\n\nif __name__ == '__main__':\n    main()",
                "utils.py": "def utility_function():\n    return 'Utility result'",
                "test_main.py": "import unittest\n\nclass TestMain(unittest.TestCase):\n    def test_main(self):\n        self.assertTrue(True)"
            })
            
            # æµ‹è¯•FilesDictæ“ä½œ
            files_success = (
                len(test_files) == 3 and
                "main.py" in test_files and
                "def main" in test_files["main.py"]
            )
            
            self.log_test(
                "æ–‡ä»¶æ“ä½œæ¨¡æ‹Ÿ",
                files_success,
                f"æ¨¡æ‹Ÿ {len(test_files)} ä¸ªæ–‡ä»¶",
                list(test_files.keys())
            )
            
            return files_success
            
        except Exception as e:
            self.log_test("æ–‡ä»¶æ“ä½œæ¨¡æ‹Ÿ", False, f"æµ‹è¯•å¤±è´¥: {str(e)}")
            return False
    
    def test_integration_context_management(self):
        """æµ‹è¯•é›†æˆä¸Šä¸‹æ–‡ç®¡ç†"""
        try:
            # æ¨¡æ‹Ÿé›†æˆä¸Šä¸‹æ–‡
            context = {
                "current_step": None,
                "step_history": [],
                "ai_feedback": [],
                "quality_metrics": [],
                "test_results": []
            }
            
            # æ¨¡æ‹Ÿæ­¥éª¤æ‰§è¡Œ
            context["current_step"] = "init"
            context["step_history"].append({
                "step": "init",
                "timestamp": "2024-01-01T00:00:00",
                "prompt": "Create a simple Python application"
            })
            
            context["ai_feedback"].append({
                "quality_score": 0.85,
                "suggestions": ["Add more comments", "Improve error handling"]
            })
            
            context["test_results"].append({
                "test_count": 3,
                "passed": 3,
                "failed": 0
            })
            
            context_success = (
                context["current_step"] == "init" and
                len(context["step_history"]) == 1 and
                len(context["ai_feedback"]) == 1 and
                len(context["test_results"]) == 1
            )
            
            self.log_test(
                "é›†æˆä¸Šä¸‹æ–‡ç®¡ç†",
                context_success,
                f"ç®¡ç† {len(context)} ä¸ªä¸Šä¸‹æ–‡å­—æ®µ",
                context
            )
            
            return context_success
            
        except Exception as e:
            self.log_test("é›†æˆä¸Šä¸‹æ–‡ç®¡ç†", False, f"æµ‹è¯•å¤±è´¥: {str(e)}")
            return False
    
    def test_compatibility_verification(self):
        """æµ‹è¯•å…¼å®¹æ€§éªŒè¯"""
        try:
            # éªŒè¯å…³é”®æ¥å£å…¼å®¹æ€§
            compatibility_checks = {
                "FilesDict_available": 'FilesDict' in globals(),
                "Path_operations": Path(__file__).exists(),
                "tempfile_support": tempfile.gettempdir() is not None,
                "json_serialization": True,  # JSONæ˜¯æ ‡å‡†åº“
                "datetime_support": True     # datetimeæ˜¯æ ‡å‡†åº“
            }
            
            compatibility_score = sum(compatibility_checks.values()) / len(compatibility_checks)
            compatibility_success = compatibility_score >= 0.8
            
            self.log_test(
                "å…¼å®¹æ€§éªŒè¯",
                compatibility_success,
                f"å…¼å®¹æ€§è¯„åˆ†: {compatibility_score:.1%}",
                compatibility_checks
            )
            
            return compatibility_success
            
        except Exception as e:
            self.log_test("å…¼å®¹æ€§éªŒè¯", False, f"éªŒè¯å¤±è´¥: {str(e)}")
            return False
    
    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸ”— å¼€å§‹æ·±åº¦é›†æˆæµ‹è¯•")
        print("=" * 60)
        
        # åŸºç¡€åŠŸèƒ½æµ‹è¯•
        self.test_mock_ai_functionality()
        self.test_deep_integration_manager()
        self.test_file_operations_simulation()
        self.test_integration_context_management()
        self.test_compatibility_verification()
        
        # é›†æˆæµç¨‹æµ‹è¯•
        self.test_simulated_deep_integration()
        
        # è¾“å‡ºæµ‹è¯•æ‘˜è¦
        self.print_test_summary()
        
        return self.passed_tests == self.total_tests
    
    def print_test_summary(self):
        """è¾“å‡ºæµ‹è¯•æ‘˜è¦"""
        print("\n" + "=" * 60)
        print("ğŸ æ·±åº¦é›†æˆæµ‹è¯•æ‘˜è¦")
        print("=" * 60)
        
        print(f"æ€»æµ‹è¯•æ•°: {self.total_tests}")
        print(f"é€šè¿‡æµ‹è¯•: {self.passed_tests}")
        print(f"å¤±è´¥æµ‹è¯•: {self.total_tests - self.passed_tests}")
        print(f"é€šè¿‡ç‡: {(self.passed_tests / self.total_tests * 100):.1f}%" if self.total_tests > 0 else "0%")
        
        print("\nè¯¦ç»†ç»“æœ:")
        for result in self.test_results:
            status = "âœ…" if result["success"] else "âŒ"
            print(f"{status} {result['name']}: {result['message']}")
        
        if self.passed_tests == self.total_tests:
            print("\nğŸ‰ æ‰€æœ‰æ·±åº¦é›†æˆæµ‹è¯•é€šè¿‡ï¼")
            print("\næ·±åº¦é›†æˆåŠŸèƒ½éªŒè¯:")
            print("âœ… GPT-ENGINEERæ ¸å¿ƒå…¼å®¹æ€§")
            print("âœ… å‡çº§ç‰ˆAIç»„ä»¶é›†æˆ")
            print("âœ… ç»Ÿä¸€ç®¡ç†æ¥å£")
            print("âœ… æ™ºèƒ½å·¥ä½œæµåè°ƒ")
            print("âœ… å‘åå…¼å®¹æ€§ä¿è¯")
        else:
            failed_count = self.total_tests - self.passed_tests
            print(f"\nâš ï¸ æœ‰ {failed_count} ä¸ªæµ‹è¯•å¤±è´¥ã€‚")
            print("è¿™å¯èƒ½æ˜¯ç¯å¢ƒé…ç½®é—®é¢˜ï¼Œæ ¸å¿ƒæ·±åº¦é›†æˆåŠŸèƒ½åŸºæœ¬å¯ç”¨ã€‚")


def main():
    """ä¸»å‡½æ•°"""
    print("æ·±åº¦é›†æˆæµ‹è¯•å·¥å…·")
    print("éªŒè¯GPT-ENGINEERä¸å‡çº§ç‰ˆAIçš„æ·±åº¦é›†æˆ")
    print("")
    
    if not HAS_DEPENDENCIES:
        print("âš ï¸ éƒ¨åˆ†ä¾èµ–ç¼ºå¤±ï¼Œå°†è¿è¡Œæ¨¡æ‹Ÿæµ‹è¯•")
        print("")
    
    tester = DeepIntegrationTester()
    success = tester.run_all_tests()
    
    print("\n" + "=" * 60)
    print("ğŸ”— æ·±åº¦é›†æˆè¯´æ˜")
    print("=" * 60)
    print("æœ¬æ¬¡å‡çº§å®ç°äº†ä»¥ä¸‹æ·±åº¦é›†æˆåŠŸèƒ½ï¼š")
    print("")
    print("1. å®Œå…¨å…¼å®¹åŸæœ‰GPT-ENGINEERæ¶æ„")
    print("   - ç»§æ‰¿SimpleAgentçš„æ‰€æœ‰åŠŸèƒ½")
    print("   - ä¿æŒåŸæœ‰APIæ¥å£ä¸å˜")
    print("   - æ”¯æŒæ‰€æœ‰ç°æœ‰å·¥ä½œæµç¨‹")
    print("")
    print("2. æ— ç¼é›†æˆå‡çº§ç‰ˆAIç»„ä»¶")
    print("   - æ™ºèƒ½ç›‘ç®¡AIå®æ—¶è´¨é‡æ£€æŸ¥")
    print("   - è‡ªåŠ¨åŒ–æµ‹è¯•AIç”Ÿæˆå’Œæ‰§è¡Œ")
    print("   - å…±äº«è®°å¿†ç³»ç»Ÿåä½œå­¦ä¹ ")
    print("")
    print("3. å¢å¼ºçš„å¼€å‘ä½“éªŒ")
    print("   - æ™ºèƒ½æç¤ºä¼˜åŒ–")
    print("   - è‡ªåŠ¨è´¨é‡æ”¹è¿›")
    print("   - è¿­ä»£ä¼˜åŒ–å¾ªç¯")
    print("   - å®æ—¶æ‰§è¡Œç›‘æ§")
    print("")
    print("4. ç»Ÿä¸€ç®¡ç†å’Œåè°ƒ")
    print("   - DeepIntegrationManagerç»Ÿä¸€ç®¡ç†")
    print("   - æ™ºèƒ½ç»„ä»¶åè°ƒ")
    print("   - æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–")
    print("")
    
    return 0 if success else 1


if __name__ == "__main__":
    sys.exit(main())